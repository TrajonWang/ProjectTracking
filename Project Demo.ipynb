{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a327ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import openai\n",
    "import os\n",
    "import yaml\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from google.cloud import texttospeech\n",
    "import os\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60944995",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    openai.api_key = config.get('api')\n",
    "    \n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/w_yy_ccc/Desktop/ProjectTracking/google_api.json'\n",
    "tts_client = texttospeech.TextToSpeechClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c005b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different functions\n",
    "def select_image():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg *.png\")])\n",
    "    if file_path:\n",
    "        image_path.set(file_path)\n",
    "\n",
    "# def select_audio():\n",
    "#     file_path = filedialog.askopenfilename(filetypes=[(\"Audio files\", \"*.mp3\")])\n",
    "#     if file_path:\n",
    "#         audio_path.set(file_path)\n",
    "\n",
    "# Record audio and transcribe it\n",
    "def record_audio():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        messagebox.showinfo(\"Recording\", \"Please start speaking...\")\n",
    "        try:\n",
    "            audio_data = recognizer.listen(source)\n",
    "            messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "            \n",
    "            # Try to recognize the audio\n",
    "            user_input = recognizer.recognize_google(audio_data)\n",
    "            audio_transcription.set(user_input)\n",
    "             \n",
    "        except sr.UnknownValueError:\n",
    "            audio_transcription.set(\"Sorry, I couldn't understand the audio. Please try again.\")\n",
    "        except sr.RequestError as e:\n",
    "            audio_transcription.set(f\"Error with the speech recognition service: {e}\")\n",
    "\n",
    "def summarize():\n",
    "    img = image_path.get()\n",
    "    txt = text_input.get(\"1.0\", tk.END).strip()\n",
    "    aud_txt = audio_transcription.get()\n",
    "\n",
    "    if not img and not aud_txt and not txt:\n",
    "        messagebox.showerror(\"Input Error\", \"Please provide at least one input (image, audio, or text).\")\n",
    "        return\n",
    "\n",
    "    prompt = f\"Image: {img}\\nAudio: {aud_txt}\\nText: {txt}\\nPlease conclude the customer's requirements from the information provided. Answer as short as possible.\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    summary_output.set(response['choices'][0]['message']['content'].strip())        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab8fa2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to play synthesized speech\n",
    "def play_audio(filename):\n",
    "    os.system(f\"afplay {filename}\")\n",
    "# Function to synthesize speech using Google Cloud Text-to-Speech\n",
    "def synthesize_speech(text, filename='output.mp3', voice_name='en-US-Journey-D'):\n",
    "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"en-US\",\n",
    "        name=voice_name,\n",
    "        ssml_gender=texttospeech.SsmlVoiceGender.MALE\n",
    "    )\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "    response = tts_client.synthesize_speech(\n",
    "        input=synthesis_input,\n",
    "        voice=voice,\n",
    "        audio_config=audio_config\n",
    "    )\n",
    "    with open(filename, 'wb') as out:\n",
    "        out.write(response.audio_content)\n",
    "    return filename\n",
    "\n",
    "# Function to handle voice interaction\n",
    "\n",
    "def voice_interaction():\n",
    "    global voice_interaction_active\n",
    "    voice_interaction_active = True\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    initial_question = \"Hello! What are we up to today?\"\n",
    "    play_audio(synthesize_speech(initial_question))\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        while voice_interaction_active:\n",
    "            try:\n",
    "                print(\"Listening for user input...\")\n",
    "                audio_data = recognizer.listen(source)\n",
    "                user_input = recognizer.recognize_google(audio_data)\n",
    "                print(f\"User said: {user_input}\")\n",
    "\n",
    "                if not voice_interaction_active:\n",
    "                    break\n",
    "\n",
    "                prompt = f\"The user said: {user_input}. Please respond appropriately.\"\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a sweet, concise assistant. You always add a sweet care message to the user at the end of each answer.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ]\n",
    "                )\n",
    "                ai_response = response['choices'][0]['message']['content'].strip()\n",
    "                print(f\"AI response: {ai_response}\")\n",
    "\n",
    "                play_audio(synthesize_speech(ai_response))\n",
    "\n",
    "            except sr.UnknownValueError:\n",
    "                error_message = \"Sorry, I didn't catch that. Please try again.\"\n",
    "                play_audio(synthesize_speech(error_message))\n",
    "            except sr.RequestError:\n",
    "                error_message = \"Sorry, there was an error with the speech recognition service.\"\n",
    "                play_audio(synthesize_speech(error_message))\n",
    "\n",
    "def start_voice_interaction():\n",
    "    threading.Thread(target=voice_interaction).start()\n",
    "\n",
    "def end_voice_interaction():\n",
    "    global voice_interaction_active\n",
    "    voice_interaction_active = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b0ed97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Summarizer\")\n",
    "\n",
    "# Define variables\n",
    "image_path = tk.StringVar()\n",
    "audio_path = tk.StringVar()\n",
    "summary_output = tk.StringVar()\n",
    "\n",
    "# Create and layout widgets\n",
    "tk.Label(root, text=\"Select Image:\").grid(row=0, column=0, padx=10, pady=10)\n",
    "tk.Entry(root, textvariable=image_path, width=50).grid(row=0, column=1, padx=10, pady=10)\n",
    "tk.Button(root, text=\"Browse\", command=select_image).grid(row=0, column=2, padx=10, pady=10)\n",
    "\n",
    "tk.Label(root, text=\"Audio Transcription:\").grid(row=1, column=0, padx=10, pady=10)\n",
    "tk.Label(root, textvariable=audio_transcription, wraplength=400, justify=\"left\").grid(row=1, column=1, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "tk.Button(root, text=\"Record Audio\", command=record_audio).grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "\n",
    "tk.Label(root, text=\"Enter Text:\").grid(row=2, column=0, padx=10, pady=10)\n",
    "text_input = tk.Text(root, height=10, width=50)\n",
    "text_input.grid(row=2, column=1, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "tk.Button(root, text=\"Summary\", command=summarize).grid(row=3, column=1, padx=10, pady=20)\n",
    "\n",
    "tk.Label(root, text=\"Summary Output:\").grid(row=4, column=0, padx=10, pady=10)\n",
    "tk.Label(root, textvariable=summary_output, wraplength=400, justify=\"left\").grid(row=4, column=1, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "# Voice interaction buttons\n",
    "tk.Button(root, text=\"Start Voice Interaction\", command=start_voice_interaction).grid(row=5, column=1, padx=10, pady=10)\n",
    "tk.Button(root, text=\"End Voice Interaction\", command=end_voice_interaction).grid(row=6, column=1, padx=10, pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e3781f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db01529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cdaff3a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
